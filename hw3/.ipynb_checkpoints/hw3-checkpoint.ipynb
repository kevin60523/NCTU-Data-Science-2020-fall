{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import imutils\n",
    "from functools import cmp_to_key\n",
    "from multiprocessing import Process, Manager, Pool, Queue, cpu_count\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPixelAnExtremum(first_subimage, second_subimage, third_subimage, threshold):\n",
    "    center_pixel_value = second_subimage[1, 1]\n",
    "    if abs(center_pixel_value) > threshold:\n",
    "        if center_pixel_value > 0:\n",
    "            return np.all(center_pixel_value >= first_subimage) and \\\n",
    "                   np.all(center_pixel_value >= third_subimage) and \\\n",
    "                   np.all(center_pixel_value >= second_subimage[0, :]) and \\\n",
    "                   np.all(center_pixel_value >= second_subimage[2, :]) and \\\n",
    "                   center_pixel_value >= second_subimage[1, 0] and \\\n",
    "                   center_pixel_value >= second_subimage[1, 2]\n",
    "        elif center_pixel_value < 0:\n",
    "            return np.all(center_pixel_value <= first_subimage) and \\\n",
    "                   np.all(center_pixel_value <= third_subimage) and \\\n",
    "                   np.all(center_pixel_value <= second_subimage[0, :]) and \\\n",
    "                   np.all(center_pixel_value <= second_subimage[2, :]) and \\\n",
    "                   center_pixel_value <= second_subimage[1, 0] and \\\n",
    "                   center_pixel_value <= second_subimage[1, 2]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradientAtCenterPixel(pixel_array):\n",
    "    dx = 0.5 * (pixel_array[1, 1, 2] - pixel_array[1, 1, 0])\n",
    "    dy = 0.5 * (pixel_array[1, 2, 1] - pixel_array[1, 0, 1])\n",
    "    ds = 0.5 * (pixel_array[2, 1, 1] - pixel_array[0, 1, 1])\n",
    "    return np.array([dx, dy, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeHessianAtCenterPixel(pixel_array):\n",
    "    center_pixel_value = pixel_array[1, 1, 1]\n",
    "    dxx = pixel_array[1, 1, 2] - 2 * center_pixel_value + pixel_array[1, 1, 0]\n",
    "    dyy = pixel_array[1, 2, 1] - 2 * center_pixel_value + pixel_array[1, 0, 1]\n",
    "    dss = pixel_array[2, 1, 1] - 2 * center_pixel_value + pixel_array[0, 1, 1]\n",
    "    dxy = 0.25 * (pixel_array[1, 2, 2] - pixel_array[1, 2, 0] - pixel_array[1, 0, 2] + pixel_array[1, 0, 0])\n",
    "    dxs = 0.25 * (pixel_array[2, 1, 2] - pixel_array[2, 1, 0] - pixel_array[0, 1, 2] + pixel_array[0, 1, 0])\n",
    "    dys = 0.25 * (pixel_array[2, 2, 1] - pixel_array[2, 0, 1] - pixel_array[0, 2, 1] + pixel_array[0, 0, 1])\n",
    "    return np.array([[dxx, dxy, dxs], \n",
    "                  [dxy, dyy, dys],\n",
    "                  [dxs, dys, dss]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeKeypointsWithOrientations(keypoint, octave_index, gaussian_image, radius_factor=3, num_bins=36, peak_ratio=0.8, scale_factor=1.5):\n",
    "    keypoints_with_orientations = []\n",
    "    image_shape = gaussian_image.shape\n",
    "    \n",
    "    scale = scale_factor * keypoint.size / np.float32(2 ** (octave_index + 1))\n",
    "    radius = int(round(radius_factor * scale))\n",
    "    weight_factor = -0.5 / (scale ** 2)\n",
    "    raw_histogram = np.zeros(num_bins)\n",
    "    smooth_histogram = np.zeros(num_bins)\n",
    "\n",
    "    for i in range(-radius, radius + 1):\n",
    "        region_y = int(round(keypoint.pt[1] / np.float32(2 ** octave_index))) + i\n",
    "        if region_y > 0 and region_y < image_shape[0] - 1:\n",
    "            for j in range(-radius, radius + 1):\n",
    "                region_x = int(round(keypoint.pt[0] / np.float32(2 ** octave_index))) + j\n",
    "                if region_x > 0 and region_x < image_shape[1] - 1:\n",
    "                    dx = gaussian_image[region_y, region_x + 1] - gaussian_image[region_y, region_x - 1]\n",
    "                    dy = gaussian_image[region_y - 1, region_x] - gaussian_image[region_y + 1, region_x]\n",
    "                    gradient_magnitude = np.sqrt(dx * dx + dy * dy)\n",
    "                    gradient_orientation = np.rad2deg(np.arctan2(dy, dx))\n",
    "                    weight = np.exp(weight_factor * (i ** 2 + j ** 2))\n",
    "                    histogram_index = int(round(gradient_orientation * num_bins / 360.))\n",
    "                    raw_histogram[histogram_index % num_bins] += weight * gradient_magnitude\n",
    "\n",
    "    for n in range(num_bins):\n",
    "        smooth_histogram[n] = (6 * raw_histogram[n] + 4 * (raw_histogram[n - 1] + raw_histogram[(n + 1) % num_bins]) + raw_histogram[n - 2] + raw_histogram[(n + 2) % num_bins]) / 16.\n",
    "    orientation_max = max(smooth_histogram)\n",
    "    orientation_peaks = np.where(np.logical_and(smooth_histogram > np.roll(smooth_histogram, 1), smooth_histogram > np.roll(smooth_histogram, -1)))[0]\n",
    "    for peak_index in orientation_peaks:\n",
    "        peak_value = smooth_histogram[peak_index]\n",
    "        if peak_value >= peak_ratio * orientation_max:\n",
    "            left_value = smooth_histogram[(peak_index - 1) % num_bins]\n",
    "            right_value = smooth_histogram[(peak_index + 1) % num_bins]\n",
    "            interpolated_peak_index = (peak_index + 0.5 * (left_value - right_value) / (left_value - 2 * peak_value + right_value)) % num_bins\n",
    "            orientation = 360. - interpolated_peak_index * 360. / num_bins\n",
    "            if abs(orientation - 360.) < 1e-7:\n",
    "                orientation = 0\n",
    "            new_keypoint = cv2.KeyPoint(*keypoint.pt, keypoint.size, orientation, keypoint.response, keypoint.octave)\n",
    "            keypoints_with_orientations.append(new_keypoint)\n",
    "    return keypoints_with_orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localizeExtremumViaQuadraticFit(i, j, image_index, octave_index, num_intervals, dog_images_in_octave, sigma, contrast_threshold, image_border_width, eigenvalue_ratio=10, num_attempts_until_convergence=5):\n",
    "    extremum_is_outside_image = False\n",
    "    image_shape = dog_images_in_octave[0].shape\n",
    "    for attempt_index in range(num_attempts_until_convergence):\n",
    "        first_image, second_image, third_image = dog_images_in_octave[image_index-1:image_index+2]\n",
    "        pixel_cube = np.stack([first_image[i-1:i+2, j-1:j+2],\n",
    "                            second_image[i-1:i+2, j-1:j+2],\n",
    "                            third_image[i-1:i+2, j-1:j+2]]).astype('float32') / 255.\n",
    "        gradient = computeGradientAtCenterPixel(pixel_cube)\n",
    "        hessian = computeHessianAtCenterPixel(pixel_cube)\n",
    "        extremum_update = -np.linalg.lstsq(hessian, gradient, rcond=None)[0]\n",
    "        if abs(extremum_update[0]) < 0.5 and abs(extremum_update[1]) < 0.5 and abs(extremum_update[2]) < 0.5:\n",
    "            break\n",
    "        j += int(round(extremum_update[0]))\n",
    "        i += int(round(extremum_update[1]))\n",
    "        image_index += int(round(extremum_update[2]))\n",
    "        if i < image_border_width or i >= image_shape[0] - image_border_width or j < image_border_width or j >= image_shape[1] - image_border_width or image_index < 1 or image_index > num_intervals:\n",
    "            extremum_is_outside_image = True\n",
    "            break\n",
    "    if extremum_is_outside_image:\n",
    "        return None\n",
    "    if attempt_index >= num_attempts_until_convergence - 1:\n",
    "        return None\n",
    "    functionValueAtUpdatedExtremum = pixel_cube[1, 1, 1] + 0.5 * np.dot(gradient, extremum_update)\n",
    "    if abs(functionValueAtUpdatedExtremum) * num_intervals >= contrast_threshold:\n",
    "        xy_hessian = hessian[:2, :2]\n",
    "        xy_hessian_trace = np.trace(xy_hessian)\n",
    "        xy_hessian_det = np.linalg.det(xy_hessian)\n",
    "        if xy_hessian_det > 0 and eigenvalue_ratio * (xy_hessian_trace ** 2) < ((eigenvalue_ratio + 1) ** 2) * xy_hessian_det:\n",
    "            keypoint = cv2.KeyPoint()\n",
    "            keypoint.pt = ((j + extremum_update[0]) * (2 ** octave_index), (i + extremum_update[1]) * (2 ** octave_index))\n",
    "            keypoint.octave = octave_index + image_index * (2 ** 8) + int(round((extremum_update[2] + 0.5) * 255)) * (2 ** 16)\n",
    "            keypoint.size = sigma * (2 ** ((image_index + extremum_update[2]) / np.float32(num_intervals))) * (2 ** (octave_index + 1))  # octave_index + 1 because the input image was doubled\n",
    "            keypoint.response = abs(functionValueAtUpdatedExtremum)\n",
    "            return keypoint, image_index\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeKeypoint_process(gaussian_images, octave_index, dog_images, threshold, contrast_threshold, image_border_width, image_index):\n",
    "    keypoints = []\n",
    "    first_image = dog_images[image_index]\n",
    "    second_image = dog_images[image_index + 1]\n",
    "    third_image = dog_images[image_index + 2]\n",
    "    for i in range(image_border_width, first_image.shape[0] - image_border_width):\n",
    "        for j in range(image_border_width, first_image.shape[1] - image_border_width):\n",
    "            if isPixelAnExtremum(first_image[i-1:i+2, j-1:j+2], second_image[i-1:i+2, j-1:j+2], third_image[i-1:i+2, j-1:j+2], threshold):\n",
    "                localization_result = localizeExtremumViaQuadraticFit(i, j, image_index + 1, octave_index, 3, dog_images, 1.6, contrast_threshold, image_border_width)\n",
    "                if localization_result is not None:\n",
    "                    keypoint, localized_image_index = localization_result\n",
    "                    keypoints_with_orientations = computeKeypointsWithOrientations(keypoint, octave_index, gaussian_images[localized_image_index])\n",
    "                    for keypoint_with_orientation in keypoints_with_orientations:\n",
    "                        keypoints.append([keypoint_with_orientation.octave, keypoint_with_orientation.pt, keypoint_with_orientation.response, keypoint_with_orientation.size, keypoint_with_orientation.angle])\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeKeypoint(gaussian_images, octave_index, dog_images, threshold, contrast_threshold):\n",
    "    image_border_width = 5\n",
    "    keypoints = []\n",
    "    manager = Manager()\n",
    "    q = manager.Queue()\n",
    "    process = []\n",
    "    for i in range(len(dog_images) - 2):\n",
    "        p = Process(target=lambda q, arg1: q.put(ComputeKeypoint_process(*arg1)), args=(q, (gaussian_images, octave_index, dog_images, threshold, contrast_threshold, image_border_width, i)))\n",
    "        process.append(p)\n",
    "        process[i].start()\n",
    "    for i in range(len(process)):\n",
    "        process[i].join()\n",
    "    while not q.empty():\n",
    "        tmp = q.get()\n",
    "        if len(tmp) != 0: \n",
    "            for keypoint in tmp:\n",
    "                keypoints.append(keypoint)\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareKeypoints(keypoint1, keypoint2):\n",
    "    if keypoint1.pt[0] != keypoint2.pt[0]:\n",
    "        return keypoint1.pt[0] - keypoint2.pt[0]\n",
    "    if keypoint1.pt[1] != keypoint2.pt[1]:\n",
    "        return keypoint1.pt[1] - keypoint2.pt[1]\n",
    "    if keypoint1.size != keypoint2.size:\n",
    "        return keypoint2.size - keypoint1.size\n",
    "    if keypoint1.angle != keypoint2.angle:\n",
    "        return keypoint1.angle - keypoint2.angle\n",
    "    if keypoint1.response != keypoint2.response:\n",
    "        return keypoint2.response - keypoint1.response\n",
    "    if keypoint1.octave != keypoint2.octave:\n",
    "        return keypoint2.octave - keypoint1.octave\n",
    "    return keypoint2.class_id - keypoint1.class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicateKeypoints(keypoints):\n",
    "    if len(keypoints) < 2:\n",
    "        return keypoints\n",
    "\n",
    "    keypoints.sort(key=cmp_to_key(compareKeypoints))\n",
    "    unique_keypoints = [keypoints[0]]\n",
    "\n",
    "    for next_keypoint in keypoints[1:]:\n",
    "        last_unique_keypoint = unique_keypoints[-1]\n",
    "        if last_unique_keypoint.pt[0] != next_keypoint.pt[0] or \\\n",
    "           last_unique_keypoint.pt[1] != next_keypoint.pt[1] or \\\n",
    "           last_unique_keypoint.size != next_keypoint.size or \\\n",
    "           last_unique_keypoint.angle != next_keypoint.angle:\n",
    "            unique_keypoints.append(next_keypoint)\n",
    "    return unique_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertKeypointsToInputImageSize(keypoints):\n",
    "    converted_keypoints = []\n",
    "    for keypoint in keypoints:\n",
    "        keypoint.pt = tuple(0.5 * np.array(keypoint.pt))\n",
    "        keypoint.size *= 0.5\n",
    "        keypoint.octave = (keypoint.octave & ~255) | ((keypoint.octave - 1) & 255)\n",
    "        converted_keypoints.append(keypoint)\n",
    "    return converted_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackOctave(keypoint):\n",
    "    octave = keypoint.octave & 255\n",
    "    layer = (keypoint.octave >> 8) & 255\n",
    "    if octave >= 128:\n",
    "        octave = octave | -128\n",
    "    scale = 1 / np.float32(1 << octave) if octave >= 0 else np.float32(1 << -octave)\n",
    "    return octave, layer, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDescriptors(keypoints, gaussian_images, num, window_width=4, num_bins=8, scale_multiplier=3, descriptor_max_value=0.2):\n",
    "    descriptors = []\n",
    "    for keypoint in keypoints:\n",
    "        octave, layer, scale = unpackOctave(keypoint)\n",
    "        gaussian_image = gaussian_images[octave + 1, layer]\n",
    "        num_rows, num_cols = gaussian_image.shape\n",
    "        point = np.round(scale * np.array(keypoint.pt)).astype('int')\n",
    "#         bins_per_degree = num_bins / 360.\n",
    "        angle = 360. - keypoint.angle\n",
    "        cos_angle = np.cos(np.deg2rad(angle))\n",
    "        sin_angle = np.sin(np.deg2rad(angle))\n",
    "#         weight_multiplier = -0.5 / ((0.5 * window_width) ** 2)\n",
    "        row_bin_list = []\n",
    "        col_bin_list = []\n",
    "        magnitude_list = []\n",
    "        orientation_bin_list = []\n",
    "        histogram_tensor = np.zeros((window_width + 2, window_width + 2, num_bins))\n",
    "\n",
    "        hist_width = scale_multiplier * 0.5 * scale * keypoint.size\n",
    "        half_width = int(np.round(hist_width * np.sqrt(2) * (window_width + 1) * 0.5))\n",
    "        half_width = int(min(half_width, np.sqrt(num_rows ** 2 + num_cols ** 2)))\n",
    "        \n",
    "        for row in range(-half_width, half_width + 1):\n",
    "            for col in range(-half_width, half_width + 1):\n",
    "                row_rot = col * sin_angle + row * cos_angle\n",
    "                col_rot = col * cos_angle - row * sin_angle\n",
    "                row_bin = (row_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                col_bin = (col_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                if row_bin > -1 and row_bin < window_width and col_bin > -1 and col_bin < window_width:\n",
    "                    window_row = int(np.round(point[1] + row))\n",
    "                    window_col = int(np.round(point[0] + col))\n",
    "                    if window_row > 0 and window_row < num_rows - 1 and window_col > 0 and window_col < num_cols - 1:\n",
    "                        dx = gaussian_image[window_row, window_col + 1] - gaussian_image[window_row, window_col - 1]\n",
    "                        dy = gaussian_image[window_row - 1, window_col] - gaussian_image[window_row + 1, window_col]\n",
    "                        gradient_magnitude = np.sqrt(dx * dx + dy * dy)\n",
    "                        gradient_orientation = np.rad2deg(np.arctan2(dy, dx)) % 360\n",
    "                        weight = np.exp(-0.125 * ((row_rot / hist_width) ** 2 + (col_rot / hist_width) ** 2))\n",
    "                        row_bin_list.append(row_bin)\n",
    "                        col_bin_list.append(col_bin)\n",
    "                        magnitude_list.append(weight * gradient_magnitude)\n",
    "                        orientation_bin_list.append((gradient_orientation - angle) * 0.0222222)\n",
    "                \n",
    "\n",
    "        for i in range(len(row_bin_list)):\n",
    "            row_bin = row_bin_list[i] \n",
    "            col_bin = col_bin_list[i] \n",
    "            magnitude = magnitude_list[i] \n",
    "            orientation_bin = orientation_bin_list[i]\n",
    "            row_bin_floor, col_bin_floor, orientation_bin_floor = np.floor([row_bin, col_bin, orientation_bin]).astype(int)\n",
    "            row_fraction, col_fraction, orientation_fraction = row_bin - row_bin_floor, col_bin - col_bin_floor, orientation_bin - orientation_bin_floor\n",
    "            if orientation_bin_floor < 0:\n",
    "                orientation_bin_floor += num_bins\n",
    "            if orientation_bin_floor >= num_bins:\n",
    "                orientation_bin_floor -= num_bins\n",
    "\n",
    "            c1 = magnitude * row_fraction\n",
    "            c0 = magnitude * (1 - row_fraction)\n",
    "            c11 = c1 * col_fraction\n",
    "            c10 = c1 * (1 - col_fraction)\n",
    "            c01 = c0 * col_fraction\n",
    "            c00 = c0 * (1 - col_fraction)\n",
    "            c111 = c11 * orientation_fraction\n",
    "            c110 = c11 * (1 - orientation_fraction)\n",
    "            c101 = c10 * orientation_fraction\n",
    "            c100 = c10 * (1 - orientation_fraction)\n",
    "            c011 = c01 * orientation_fraction\n",
    "            c010 = c01 * (1 - orientation_fraction)\n",
    "            c001 = c00 * orientation_fraction\n",
    "            c000 = c00 * (1 - orientation_fraction)\n",
    "\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 1, orientation_bin_floor] += c000\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 1, (orientation_bin_floor + 1) % num_bins] += c001\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 2, orientation_bin_floor] += c010\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 2, (orientation_bin_floor + 1) % num_bins] += c011\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 1, orientation_bin_floor] += c100\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 1, (orientation_bin_floor + 1) % num_bins] += c101\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 2, orientation_bin_floor] += c110\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 2, (orientation_bin_floor + 1) % num_bins] += c111\n",
    "\n",
    "        descriptor_vector = histogram_tensor[1:-1, 1:-1, :].flatten()\n",
    "        threshold = np.linalg.norm(descriptor_vector) * descriptor_max_value\n",
    "        descriptor_vector[descriptor_vector > threshold] = threshold\n",
    "        descriptor_vector /= max(np.linalg.norm(descriptor_vector), 1e-7)\n",
    "        descriptor_vector = np.round(512 * descriptor_vector)\n",
    "        descriptor_vector[descriptor_vector < 0] = 0\n",
    "        descriptor_vector[descriptor_vector > 255] = 255\n",
    "        descriptors.append(descriptor_vector)\n",
    "    \n",
    "    return (num, np.array(descriptors, dtype='float32'))\n",
    "#     return_dict[num] = descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeKeypointsandDescriptors(img):\n",
    "    # get based image with pre-smooth\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    img = img.astype('float32') \n",
    "    img = cv2.resize(img, (0, 0), fx=2, fy=2, interpolation=cv2.INTER_LINEAR) # lowe recommend to double image to store info\n",
    "    sigma = 1.6 #recommend\n",
    "    assumed_blur = 0.5 #paper assumed\n",
    "    sigma_diff = np.sqrt((sigma ** 2) - ((2 * assumed_blur) ** 2)) # assumed blur * 2 because double the image size\n",
    "    based_img = cv2.GaussianBlur(img, (0, 0), sigmaX=sigma_diff, sigmaY=sigma_diff) # modify image to blur with sigma 1.6\n",
    "    \n",
    "    s = 3 # customized\n",
    "    num_octaves = int(np.round(np.log(min(based_img.shape)) / np.log(2) - 1)) # opencv default????????\n",
    "    \n",
    "    # compute gaussian blur image for each octave\n",
    "    num_images_per_octave = s + 3\n",
    "    k = 2 ** (1. / s)    \n",
    "    gaussian_images = []\n",
    "    compute_img = based_img.copy()\n",
    "    for octave_index in range(num_octaves):\n",
    "        gaussian_images_in_octave = []\n",
    "        gaussian_images_in_octave.append(compute_img)\n",
    "        for i in range(num_images_per_octave-1):\n",
    "            gaussian_images_in_octave.append(cv2.GaussianBlur(compute_img, (0, 0), sigmaX=sigma * (k ** (i-1)), sigmaY=sigma * (k ** (i-1))))\n",
    "        gaussian_images.append(gaussian_images_in_octave)\n",
    "        compute_img = cv2.resize(compute_img, (int(compute_img.shape[1] / 2), int(compute_img.shape[0] / 2)), interpolation=cv2.INTER_NEAREST)\n",
    "    gaussian_images = np.array(gaussian_images)\n",
    "    \n",
    "    # compute dog image\n",
    "    dog_images = []\n",
    "    for gaussian_images_in_octave in gaussian_images:\n",
    "        dog_images_in_octave = []\n",
    "        for first_image, second_image in zip(gaussian_images_in_octave, gaussian_images_in_octave[1:]):\n",
    "            dog_images_in_octave.append(cv2.subtract(second_image, first_image))\n",
    "        dog_images.append(dog_images_in_octave)\n",
    "    dog_images = np.array(dog_images)\n",
    "    strat = time.time()\n",
    "    # compute keypoint\n",
    "    contrast_threshold = 0.04\n",
    "    threshold = np.floor(0.5 * contrast_threshold / s * 255)\n",
    "    start = time.time()\n",
    "    manager = Manager()\n",
    "    q = manager.Queue()\n",
    "    process = []\n",
    "    for octave_index in range(len(dog_images)):\n",
    "        p = Process(target=lambda q, arg1: q.put(ComputeKeypoint(*arg1)), args=(q, (gaussian_images[octave_index], octave_index, dog_images[octave_index], threshold, contrast_threshold)))\n",
    "        process.append(p)\n",
    "        process[octave_index].start()\n",
    "    for i in range(len(process)):\n",
    "        process[i].join()\n",
    "    \n",
    "    print('keypoint: ', time.time() - start)\n",
    "    start = time.time()\n",
    "    keypoints = []\n",
    "    while not q.empty():\n",
    "        for keypoint in q.get():\n",
    "            tmp = cv2.KeyPoint()\n",
    "            tmp.octave = keypoint[0]\n",
    "            tmp.pt = keypoint[1]\n",
    "            tmp.response = keypoint[2]\n",
    "            tmp.size = keypoint[3]\n",
    "            tmp.angle = keypoint[4]\n",
    "            keypoints.append(tmp)\n",
    "    print('append: ', time.time() - start)\n",
    "    keypoints = removeDuplicateKeypoints(keypoints)\n",
    "    keypoints = convertKeypointsToInputImageSize(keypoints)\n",
    "    start = time.time()\n",
    "\n",
    "    manager = Manager()\n",
    "    q = manager.Queue()\n",
    "    process = []\n",
    "    keypoints_number = len(keypoints)\n",
    "    count = min(keypoints_number, cpu_count())\n",
    "    per_process = int(keypoints_number / count)\n",
    "    for i in range(count):\n",
    "        down = per_process * i\n",
    "        up = per_process * (i+1)\n",
    "        if up > keypoints_number:\n",
    "            up = keypoints_number\n",
    "        p = Process(target=lambda q, arg1: q.put(generateDescriptors(*arg1)), args=(q ,(keypoints[down:up], gaussian_images, i)))\n",
    "        process.append(p)\n",
    "        process[i].start()\n",
    "    for i in range(len(process)):\n",
    "        process[i].join()\n",
    "    \n",
    "    descriptors_no_order = []\n",
    "    descriptors = []\n",
    "    while not q.empty():\n",
    "        descriptors_no_order.append(q.get())\n",
    "    descriptors_order = sorted(descriptors_no_order, key=lambda x: x[0])\n",
    "    for descriptor in descriptors_order:\n",
    "        descriptors.append(descriptor[1])\n",
    "    descriptors = np.concatenate(descriptors, axis=0)\n",
    "    print('desciptors: ', time.time() - start)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_img = []\n",
    "def read_directory(directory_name):\n",
    "    filenumber = len([name for name in os.listdir(directory_name) if os.path.isfile(os.path.join(directory_name, name))])\n",
    "    for i in range(1,filenumber+1):\n",
    "        img = cv2.imread(directory_name + \"/\" + str(i)+\".jpg\")\n",
    "        array_of_img.append(img)\n",
    "def linearBlendingWithConstantWidth(imgs):\n",
    "        '''\n",
    "        linear Blending with Constat Width, avoiding ghost region\n",
    "        # you need to determine the size of constant with\n",
    "        '''\n",
    "        img_left, img_right = imgs\n",
    "        (hl, wl) = img_left.shape[:2]\n",
    "        (hr, wr) = img_right.shape[:2]\n",
    "        img_left_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        img_right_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        constant_width = 3 # constant width\n",
    "        \n",
    "        # find the left image and right image mask region(Those not zero pixels)\n",
    "        for i in range(hl):\n",
    "            for j in range(wl):\n",
    "                if np.count_nonzero(img_left[i, j]) > 0:\n",
    "                    img_left_mask[i, j] = 1\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if np.count_nonzero(img_right[i, j]) > 0:\n",
    "                    img_right_mask[i, j] = 1\n",
    "                    \n",
    "        # find the overlap mask(overlap region of two image)\n",
    "        overlap_mask = np.zeros((hr, wr), dtype=\"int\")\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(img_left_mask[i, j]) > 0 and np.count_nonzero(img_right_mask[i, j]) > 0):\n",
    "                    overlap_mask[i, j] = 1\n",
    "        \n",
    "        # compute the alpha mask to linear blending the overlap region\n",
    "        alpha_mask = np.zeros((hr, wr)) # alpha value depend on left image\n",
    "        for i in range(hr):\n",
    "            minIdx = maxIdx = -1\n",
    "            for j in range(wr):\n",
    "                if (overlap_mask[i, j] == 1 and minIdx == -1):\n",
    "                    minIdx = j\n",
    "                if (overlap_mask[i, j] == 1):\n",
    "                    maxIdx = j\n",
    "            \n",
    "            if (minIdx == maxIdx): # represent this row's pixels are all zero, or only one pixel not zero\n",
    "                continue\n",
    "                \n",
    "            decrease_step = 1 / (maxIdx - minIdx)\n",
    "            \n",
    "            # Find the middle line of overlapping regions, and only do linear blending to those regions very close to the middle line.\n",
    "            middleIdx = int((maxIdx + minIdx) / 2)\n",
    "            \n",
    "            # left \n",
    "            for j in range(minIdx, middleIdx + 1):\n",
    "                if (j >= middleIdx - constant_width):\n",
    "                    alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "                else:\n",
    "                    alpha_mask[i, j] = 1\n",
    "            # right\n",
    "            for j in range(middleIdx + 1, maxIdx + 1):\n",
    "                if (j <= middleIdx + constant_width):\n",
    "                    alpha_mask[i, j] = 1 - (decrease_step * (j - minIdx))\n",
    "                else:\n",
    "                    alpha_mask[i, j] = 0\n",
    "\n",
    "        \n",
    "        linearBlendingWithConstantWidth_img = np.copy(img_right)\n",
    "        linearBlendingWithConstantWidth_img[:hl, :wl] = np.copy(img_left)\n",
    "        # linear blending with constant width\n",
    "        for i in range(hr):\n",
    "            for j in range(wr):\n",
    "                if (np.count_nonzero(overlap_mask[i, j]) > 0):\n",
    "                    linearBlendingWithConstantWidth_img[i, j] = alpha_mask[i, j] * img_left[i, j] + (1 - alpha_mask[i, j]) * img_right[i, j]\n",
    "        \n",
    "        return linearBlendingWithConstantWidth_img        \n",
    "\n",
    "def warpImages(img1, img2, H):\n",
    "    rows1, cols1 = img1.shape[:2]\n",
    "    rows2, cols2 = img2.shape[:2]\n",
    "\n",
    "    list_of_points_1 = np.float32([[0,0], [0, rows1],[cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
    "    temp_points = np.float32([[0,0], [0,rows2], [cols2,rows2], [cols2,0]]).reshape(-1,1,2)\n",
    "\n",
    "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
    "\n",
    "    list_of_points = np.concatenate((list_of_points_1,list_of_points_2), axis=0)\n",
    "\n",
    "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
    "  \n",
    "    translation_dist = [-x_min, -y_min]\n",
    "  \n",
    "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "\n",
    "    output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
    "    output_img = linearBlendingWithConstantWidth([img1, output_img])\n",
    "#     output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
    "    return output_img, output_img.shape[1], output_img.shape[0], H_translation\n",
    "   \n",
    "def cylindricalWarp(img, K):\n",
    "    \"\"\"This function returns the cylindrical warp for a given image and intrinsics matrix K\"\"\"\n",
    "    h_,w_ = img.shape[:2]\n",
    "    # pixel coordinates\n",
    "    y_i, x_i = np.indices((h_,w_))\n",
    "    X = np.stack([x_i,y_i,np.ones_like(x_i)],axis=-1).reshape(h_*w_,3) # to homog\n",
    "    Kinv = np.linalg.inv(K) \n",
    "    X = Kinv.dot(X.T).T # normalized coords\n",
    "    # calculate cylindrical coords (sin\\theta, h, cos\\theta)\n",
    "    A = np.stack([np.sin(X[:,0]),X[:,1],np.cos(X[:,0])],axis=-1).reshape(w_*h_,3)\n",
    "    B = K.dot(A.T).T # project back to image-pixels plane\n",
    "    # back from homog coords\n",
    "    B = B[:,:-1] / B[:,[-1]]\n",
    "    # make sure warp coords only within image bounds\n",
    "    B[(B[:,0] < 0) | (B[:,0] >= w_) | (B[:,1] < 0) | (B[:,1] >= h_)] = -1\n",
    "    B = B.reshape(h_,w_,-1)\n",
    "    \n",
    "    img_rgba = cv2.cvtColor(img,cv2.COLOR_BGR2BGRA) # for transparent borders...\n",
    "    # warp the image according to cylindrical coords\n",
    "    return cv2.remap(img_rgba, B[:,:,0].astype(np.float32), B[:,:,1].astype(np.float32), cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n",
    "    \n",
    "def trim(frame):\n",
    "    \n",
    "    #crop top\n",
    "    if not np.sum(frame[0]):\n",
    "        return trim(frame[1:])\n",
    "    #crop top\n",
    "    if not np.sum(frame[-1]):\n",
    "        return trim(frame[:-2])\n",
    "    #crop top\n",
    "    if not np.sum(frame[:,0]):\n",
    "        return trim(frame[:,1:])\n",
    "    #crop top\n",
    "    if not np.sum(frame[:,-1]):\n",
    "        return trim(frame[:,:-2])\n",
    "#     for i in range(frame.shape[1]):\n",
    "# #         ran = np.random.randint(frame.shape[0], size=10)\n",
    "#         black = True\n",
    "#         for j in range(5):\n",
    "#             if (frame[j][i] != np.array([0,0,0])).all():\n",
    "#                 black = False\n",
    "#             if (frame[frame.shape[0] - j - 1][i] != np.array([0,0,0])).all():\n",
    "#                 black = False\n",
    "#         if black == True:\n",
    "#             if (frame[0][i] == np.array([0,0,0])).all():\n",
    "#                 if i == 0:\n",
    "#                     return trim(frame[:, 1:])\n",
    "#                 if i == frame.shape[1] - 1:\n",
    "#                     return trim(frame[:, :-2])\n",
    "#                 else:\n",
    "#                     return trim(np.concatenate((frame[:, :i-1], frame[:, i+1:]), axis=1))\n",
    "#             if (frame[-1][i] == np.array([0,0,0])).all():\n",
    "#                 if i == 0:\n",
    "#                     return trim(frame[:, 1:])\n",
    "#                 if i == frame.shape[1] - 1:\n",
    "#                     return trim(frame[:, :-2])\n",
    "#                 else:\n",
    "#                     return trim(np.concatenate((frame[:, :i-1], frame[:, i+1:]), axis=1))\n",
    "    return frame\n",
    "\n",
    "def SIFT(inputname):\n",
    "    read_directory(inputname)\n",
    "    h, w = array_of_img[0].shape[:2]\n",
    "    K = np.array([[800,0,w/2],[0,800,h/2],[0,0,1]]) # mock intrinsics\n",
    "    for i in range(len(array_of_img)):\n",
    "        array_of_img[i] = trim(cylindricalWarp(array_of_img[i], K))\n",
    "        array_of_img[i] = trim(array_of_img[i])\n",
    "\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for i in range(len(array_of_img)):\n",
    "        tmp_keypoint, tmp_descriptor = sift.detectAndCompute(array_of_img[i], None)\n",
    "        keypoints.append(tmp_keypoint)\n",
    "        descriptors.append(tmp_descriptor)\n",
    "    homography= []\n",
    "    for i in range(len(keypoints)-1):\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "        matches = bf.match(descriptors[i], descriptors[i+1])\n",
    "        matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "        src_pts = np.float32([keypoints[i][m.queryIdx].pt for m in matches[:50]]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([keypoints[i+1][m.trainIdx].pt for m in matches[:50]]).reshape(-1,1,2)\n",
    "        M, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)        \n",
    "        homography.append(M)\n",
    "\n",
    "    all_var_width = []\n",
    "    all_var_height = []\n",
    "    for i in range(len(homography)):\n",
    "        top = np.array([[array_of_img[i].shape[1], 0], [0, 0]], dtype=np.float)\n",
    "        new_top = cv2.perspectiveTransform(top[None, :, :], homography[i])\n",
    "        var_width = new_top[0][0][0] - new_top[0][1][0]\n",
    "        all_var_width.append(var_width)\n",
    "        translation_dist = [var_width, 0]\n",
    "        W_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "        \n",
    "        top = np.array([[0, array_of_img[i].shape[0]], [0, 0]], dtype=np.float)\n",
    "        new_top = cv2.perspectiveTransform(top[None, :, :], homography[i])\n",
    "        var_height = new_top[0][0][1] - new_top[0][1][1]\n",
    "        all_var_height.append(var_height)\n",
    "        translation_dist = [0, var_height]\n",
    "        H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "        \n",
    "        for j in range(i+1, len(homography)):\n",
    "            homography[j] = W_translation.dot(homography[j])\n",
    "            homography[j] = H_translation.dot(homography[j])\n",
    "            \n",
    "    for i in range(1, len(array_of_img)):\n",
    "        original_width = array_of_img[0].shape[1]\n",
    "        original_height = array_of_img[0].shape[0]\n",
    "        tmp, width_of_tmp, height_of_tmp, translation = warpImages(array_of_img[0], array_of_img[i], homography[i-1])\n",
    "        array_of_img[0] = trim(tmp)\n",
    "        var = original_width +  all_var_width[i-1] - width_of_tmp\n",
    "        translation_dist = [-var, 0]\n",
    "        H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "        \n",
    "        var = original_height + all_var_height[i-1] - height_of_tmp\n",
    "        translation_dist = [0, -var]\n",
    "        W_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "        \n",
    "        for j in range(i, len(homography)):\n",
    "            homography[j] = H_translation.dot(homography[j])\n",
    "            homography[j] = W_translation.dot(homography[j])\n",
    "            homography[j] = translation.dot(homography[j])\n",
    "    imageoutput = array_of_img[0]\n",
    "    array_of_img.clear()\n",
    "    return imageoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoint:  26.340100288391113\n",
      "append:  0.01164555549621582\n",
      "3372\n",
      "desciptors:  41.79018473625183\n",
      "68.22985029220581\n",
      "keypoint:  30.28913974761963\n",
      "append:  0.015627622604370117\n",
      "3912\n",
      "desciptors:  48.55080723762512\n",
      "keypoint:  30.630669116973877\n",
      "append:  0.013926267623901367\n",
      "3912\n",
      "desciptors:  49.39787197113037\n",
      "80.12128973007202\n"
     ]
    }
   ],
   "source": [
    "f = open('testfile.txt', 'r')\n",
    "dirname = str(f.readline()).strip()\n",
    "while(dirname):\n",
    "    start = time.time()\n",
    "    imageout=SIFT(dirname)\n",
    "    print(time.time()-start)\n",
    "    plt.figure()\n",
    "    plt.imshow(imageout)\n",
    "    cv2.imwrite(dirname+'.jpg', imageout)\n",
    "    dirname = str(f.readline()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
